#!/usr/bin/env python3

"""
Audio Transcription Script using OpenAI Whisper
Transcribes single file or batch-processes all audio files in a directory.
Supports Sequential (accurate) and Chunked (fast, parallel) modes.
"""

import torch
import whisper
import argparse
from pathlib import Path
import math
import numpy as np
import multiprocessing
from concurrent.futures import ProcessPoolExecutor, as_completed

# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∞—É–¥–∏–æ-—Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
AUDIO_EXTENSIONS = {".mp3", ".wav", ".m4a", ".flac", ".ogg", ".wma", ".aac", ".opus"}

def get_audio_files(directory: Path, extensions=None):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (–±–µ–∑ —Ä–µ–∫—É—Ä—Å–∏–∏)."""
    extensions = extensions or AUDIO_EXTENSIONS
    files = [f for f in directory.iterdir() if f.is_file() and f.suffix.lower() in extensions]
    return sorted(files)

# --- Chunked Processing Logic ---

worker_model = None

def _init_worker(model_name):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–æ—Ä–∫–µ—Ä–∞: –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –æ–¥–∏–Ω —Ä–∞–∑ –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å."""
    global worker_model
    # print(f"[WORKER] –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name} –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ {multiprocessing.current_process().name}...")
    worker_model = whisper.load_model(model_name)

def _process_chunk(chunk_data, language):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∫—É—Å–∫–∞ –∞—É–¥–∏–æ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ."""
    # chunk_data - numpy array
    global worker_model
    try:
        # –î–ª—è whisper.transcribe –Ω—É–∂–µ–Ω float32 numpy array
        result = worker_model.transcribe(chunk_data, language=language)
        return result["text"].strip()
    except Exception as e:
        return f"[ERROR: {e}]"

def transcribe_file_chunked(audio_path: Path, model_name, language, chunk_size_sec=60, workers=2, verbose=False, output_path=None):
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Ñ–∞–π–ª–∞ –ø–æ –∫—É—Å–∫–∞–º (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)."""
    try:
        print(f"[STATUS] PREPARING CHUNKED ({workers} workers, {chunk_size_sec}s chunks)", flush=True)
        print(f"‚öô –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è: {audio_path.name}", flush=True)

        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ —Ü–µ–ª–∏–∫–æ–º
        audio = whisper.load_audio(str(audio_path))
        sample_rate = whisper.audio.SAMPLE_RATE
        total_duration = audio.shape[0] / sample_rate
        print(f"[DURATION] {total_duration:.2f}s", flush=True)

        if total_duration < chunk_size_sec:
             # –ï—Å–ª–∏ —Ñ–∞–π–ª –∫–æ—Ä–æ—á–µ –∫—É—Å–∫–∞, –ø—Ä–æ—â–µ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (–Ω–æ —á–µ—Ä–µ–∑ —Ç—É –∂–µ –ª–æ–≥–∏–∫—É)
             chunks = [audio]
        else:
            # 2. –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∫—É—Å–∫–∏
            chunk_samples = int(chunk_size_sec * sample_rate)
            chunks = []
            for i in range(0, len(audio), chunk_samples):
                chunks.append(audio[i : i + chunk_samples])
            print(f"[CHUNKS] –§–∞–π–ª —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} —á–∞—Å—Ç–µ–π", flush=True)

        # 3. –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º ProcessPoolExecutor
        full_text_parts = [None] * len(chunks)

        # NOTE: max_workers –Ω–µ –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–≤—ã—à–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤, –∏–Ω–∞—á–µ –∑—Ä—è –ø–æ–¥–Ω–∏–º–µ–º –ø—Ä–æ—Ü–µ—Å—Å—ã
        actual_workers = min(workers, len(chunks))

        with ProcessPoolExecutor(max_workers=actual_workers, initializer=_init_worker, initargs=(model_name,)) as executor:
            futures = {}
            for i, chunk in enumerate(chunks):
                future = executor.submit(_process_chunk, chunk, language)
                futures[future] = i

            for future in as_completed(futures):
                idx = futures[future]
                try:
                    text_part = future.result()
                    full_text_parts[idx] = text_part
                    if verbose:
                        print(f"  [Chunk {idx+1}/{len(chunks)}] ok")
                except Exception as e:
                     print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∫—É—Å–∫–µ {idx+1}: {e}")
                     full_text_parts[idx] = ""

        final_text = " ".join([t for t in full_text_parts if t])

        if output_path:
            output_path.write_text(final_text, encoding="utf-8")
            print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}", flush=True)
        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ CHUNKED –æ–±—Ä–∞–±–æ—Ç–∫–µ {audio_path}: {e}", flush=True)
        # import traceback
        # traceback.print_exc()
        return False


def transcribe_file_sequential(model, audio_path: Path, language, verbose=False, output_path=None):
    """–û–±—ã—á–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)."""
    try:
        print(f"[STATUS] PREPARING SEQUENTIAL", flush=True)
        print(f"‚öô –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è: {audio_path.name}", flush=True)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ —Å–∞–º–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        audio = whisper.load_audio(str(audio_path))
        duration = audio.shape[0] / whisper.audio.SAMPLE_RATE
        print(f"[DURATION] {duration:.2f}s", flush=True)

        result = model.transcribe(audio, language=language, verbose=verbose)
        text = result["text"].strip()

        if output_path:
            output_path.write_text(text, encoding="utf-8")
            print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}", flush=True)
        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {audio_path}: {e}", flush=True)
        return False


def main():
    parser = argparse.ArgumentParser(description="üéôÔ∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ (Sequential / Chunked)")

    parser.add_argument(
        "--file", type=str,
        help="‚ñ∂ –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"
    )
    parser.add_argument(
        "--lang", type=str, default="ru",
        help='‚ñ∑ –Ø–∑—ã–∫ –∞—É–¥–∏–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: "ru")'
    )
    parser.add_argument(
        "--output", type=str, default="transcribe.txt",
        help='‚òÖ –§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞)'
    )
    parser.add_argument(
        "--live", action="store_true", default=False,
        help="‚ñ¢ –í—ã–≤–æ–¥ –ø—Ä–æ—Ü–µ—Å—Å–∞ (verbose)"
    )
    parser.add_argument(
        "--multiple", action="store_true", default=False,
        help="‚òÖ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é"
    )

    # –ù–æ–≤—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    parser.add_argument(
        "--method", type=str, choices=["sequential", "chunked"], default="sequential",
        help="‚öô –ú–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏: sequential (—Ç–æ—á–Ω–æ, –º–µ–¥–ª–µ–Ω–Ω–æ) –∏–ª–∏ chunked (–±—ã—Å—Ç—Ä–æ, –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)"
    )
    parser.add_argument(
        "--workers", type=int, default=2,
        help="‚ö° –ö–æ–ª-–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è chunked —Ä–µ–∂–∏–º–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 2)"
    )
    parser.add_argument(
        "--chunk_size", type=int, default=60,
        help="‚úÇ –†–∞–∑–º–µ—Ä –∫—É—Å–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –¥–ª—è chunked —Ä–µ–∂–∏–º–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 60)"
    )
    parser.add_argument(
        "--model", type=str, default="small",
        help="üß† –ú–æ–¥–µ–ª—å whisper (tiny, base, small, medium, large)"
    )

    args = parser.parse_args()

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–µ—Ç–æ–¥–∞ –∑–∞–ø—É—Å–∫–∞ –¥–ª—è multiprocessing
    # Whisper/Torch + Multiprocessing –∏–Ω–æ–≥–¥–∞ –≤—ã–∑—ã–≤–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å 'fork'. 'spawn' –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ.
    try:
        multiprocessing.set_start_method('spawn')
    except RuntimeError:
        pass # –£–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ

    # Sequential —Ç—Ä–µ–±—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ –í –ì–õ–ê–í–ù–û–ú –ø–æ—Ç–æ–∫–µ
    # Chunked –∑–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –í –í–û–ö–ï–†–ê–•
    model = None
    if args.method == "sequential":
        print(f"‚ãØ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ '{args.model}' (Main Process)...")
        model = whisper.load_model(args.model)
    else:
        print(f"‚Ñπ –í —Ä–µ–∂–∏–º–µ Chunked –º–æ–¥–µ–ª—å '{args.model}' –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ –∫–∞–∂–¥–æ–º –∏–∑ {args.workers} –≤–æ—Ä–∫–µ—Ä–æ–≤.")

    language = args.lang or None

    # --- –õ–æ–≥–∏–∫–∞ –≤—ã–±–æ—Ä–∞ —Ñ–∞–π–ª–æ–≤ ---
    targets = []
    if args.multiple:
        directory = Path(args.file) if args.file else Path(".")
        if directory.is_dir():
            files = get_audio_files(directory)
            for f in files:
                targets.append((f, f.with_suffix(".txt")))
            print(f"‚ñ¢ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(targets)}")
        else:
            print("‚ùå –£–∫–∞–∑–∞–Ω–Ω—ã–π –ø—É—Ç—å –Ω–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è")
            return
    else:
        if not args.file:
             parser.error("--file –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")
        p = Path(args.file)
        if p.exists():
             targets.append((p, Path(args.output)))
        else:
             print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
             return

    print(f"\n‚òÖ –°—Ç–∞—Ä—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(targets)} —Ñ–∞–π–ª–æ–≤ | –ú–µ—Ç–æ–¥: {args.method.upper()}\n")

    success_count = 0
    for i, (inp, out) in enumerate(targets, 1):
        print(f"‚ñ∑ [{i}/{len(targets)}] {inp.name}")

        ok = False
        if args.method == "sequential":
             ok = transcribe_file_sequential(model, inp, language, verbose=args.live, output_path=out)
        else:
             ok = transcribe_file_chunked(
                 inp,
                 model_name=args.model,
                 language=language,
                 chunk_size_sec=args.chunk_size,
                 workers=args.workers,
                 verbose=args.live,
                 output_path=out
             )

        if ok: success_count += 1

    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ: {success_count}/{len(targets)} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")

if __name__ == "__main__":
    main()